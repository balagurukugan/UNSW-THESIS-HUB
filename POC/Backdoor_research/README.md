# Backdoor Attacks and Data Poisoning - Proof of Concept

This project is a Python-based proof-of-concept experiment for backdoor attacks and data poisoning in neural networks. It demonstrates the following:

1. **Backdoor Injection**: Injecting backdoors into neural network models.

## Dataset
The project uses datasets like CIFAR-10 or MNIST to ensure diversity and uniqueness in experimentation.

## Structure
- `injection/`: Scripts for injecting backdoors.

## Requirements
- Python 3.8+
- Required Python packages are listed in `requirements.txt`.

## Setup
1. Clone the repository.
2. Install dependencies using `pip install -r requirements.txt`.
3. Run the scripts in the directories to perform experiments.

## Disclaimer
This project is for educational and research purposes only. Use responsibly.